from __future__ import annotations

import os
from typing import Any, Dict

import torch
import torch.nn as nn
import yaml
from transformers import AutoConfig, AutoModel, AutoTokenizer, PreTrainedModel

from utils.logger import logger

CONFIG_PATH = os.path.join(
    os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))),
    "config", "config.yaml",
)


def _load_config() -> dict:
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


# ------------------------------------------------------------------
# Custom model class required by desklib/ai-text-detector-v1.01
# ------------------------------------------------------------------

class _DesklibAIDetectionModel(PreTrainedModel):
    """Custom architecture for the Desklib AI text detector.

    Architecture: DeBERTa-v3-large → mean pooling → linear(hidden→1) → sigmoid
    Output: single logit where sigmoid(logit) ≥ 0.5  →  AI-generated
    """

    config_class = AutoConfig

    def __init__(self, config: AutoConfig) -> None:
        super().__init__(config)
        self.model = AutoModel.from_config(config)
        self.classifier = nn.Linear(config.hidden_size, 1)
        self.init_weights()

    def forward(
        self,
        input_ids: torch.Tensor,
        attention_mask: torch.Tensor | None = None,
        labels: torch.Tensor | None = None,
    ) -> Dict[str, torch.Tensor]:
        outputs = self.model(input_ids, attention_mask=attention_mask)
        last_hidden_state = outputs[0]

        # Mean pooling over non-padding tokens
        mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()
        sum_embeddings = torch.sum(last_hidden_state * mask_expanded, dim=1)
        sum_mask = torch.clamp(mask_expanded.sum(dim=1), min=1e-9)
        pooled = sum_embeddings / sum_mask

        logits = self.classifier(pooled)

        result: Dict[str, torch.Tensor] = {"logits": logits}
        if labels is not None:
            loss_fn = nn.BCEWithLogitsLoss()
            result["loss"] = loss_fn(logits.view(-1), labels.float())
        return result


class TextAIDetector:
    """Detects whether a piece of text was generated by an AI model.

    Uses the desklib/ai-text-detector-v1.01 model (DeBERTa-v3-large
    fine-tuned for modern AI text detection, #1 on RAID Benchmark).
    """

    def __init__(self) -> None:
        cfg = _load_config()
        text_cfg = cfg["text"]
        self.model_name: str = text_cfg["model_name"]
        self.max_length: int = text_cfg.get("max_length", 768)
        self.threshold: float = text_cfg.get("threshold", 0.5)
        self.device = torch.device(
            cfg.get("device", "cuda") if torch.cuda.is_available() else "cpu"
        )

        logger.info("Loading text model '%s' on %s", self.model_name, self.device)
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = _DesklibAIDetectionModel.from_pretrained(self.model_name, low_cpu_mem_usage=True)
        self.model.to(self.device)
        self.model.eval()

        logger.info("Text model loaded (architecture=DesklibAIDetectionModel, threshold=%.2f)", self.threshold)

    @torch.no_grad()
    def predict(self, text: str) -> Dict[str, Any]:
        """Classify *text* as human-written or AI-generated.

        Returns a dict with:
            - label            : "ai-generated" or "human-written"
            - confidence       : probability of the predicted label
            - ai_probability   : probability the text is AI-generated
            - human_probability: probability the text is human-written
        """
        if not text or not text.strip():
            logger.warning("Empty text provided for AI-text detection")
            return {
                "label": "unknown",
                "confidence": 0.0,
                "ai_probability": 0.0,
                "human_probability": 0.0,
            }

        logger.info("Tokenising input text (length=%d chars, max_length=%d)", len(text), self.max_length)
        inputs = self.tokenizer(
            text,
            return_tensors="pt",
            truncation=True,
            max_length=self.max_length,
            padding="max_length",
        )
        inputs = {k: v.to(self.device) for k, v in inputs.items()}

        outputs = self.model(
            input_ids=inputs["input_ids"],
            attention_mask=inputs["attention_mask"],
        )
        logits = outputs["logits"]
        ai_prob = round(torch.sigmoid(logits).item(), 4)
        human_prob = round(1.0 - ai_prob, 4)

        if ai_prob >= self.threshold:
            label = "ai-generated"
            confidence = ai_prob
        else:
            label = "human-written"
            confidence = human_prob

        result: Dict[str, Any] = {
            "label": label,
            "confidence": confidence,
            "ai_probability": ai_prob,
            "human_probability": human_prob,
        }

        logger.info("Text result: label=%s, confidence=%.4f (ai=%.4f, human=%.4f)",
                     label, confidence, ai_prob, human_prob)
        return result
